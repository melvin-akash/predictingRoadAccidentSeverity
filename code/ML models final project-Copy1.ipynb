{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ee083c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39123f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dataset\n",
    "dataset_path = '/Users/melvinakash/Desktop/NCI/ric/final_eda_output.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1518a6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "data = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4729a94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['a_ref', 'a_veh', 'a_cas', 'a_wkday', 'a_day', 'a_month', 'a_hour',\n",
       "       'a_min', 'a_gd1', 'a_gd2', 'a_ctype', 'a_speed', 'c_class', 'c_sex',\n",
       "       'c_agegroup', 'c_school', 'c_vtype', 'v_type', 'v_tow', 'v_man',\n",
       "       'v_loc', 'v_impact', 'v_sex', 'v_agegroup', 'v_hitr', 'a_District_ANTN',\n",
       "       'a_District_ARBC', 'a_District_ARND', 'a_District_BELC',\n",
       "       'a_District_CCGL', 'a_District_DCST', 'a_District_FERO',\n",
       "       'a_District_LISC', 'a_District_MEAN', 'a_District_MIDU',\n",
       "       'a_District_NEMD', 'a_type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a06abb5",
   "metadata": {},
   "source": [
    "# Target variable distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "749880ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a_type\n",
       "3         34270\n",
       "2          5826\n",
       "1           622\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['a_type']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e52627",
   "metadata": {},
   "source": [
    "# Over Sampling using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f83d4f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melvinakash/miniconda3/lib/python3.10/site-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (34000) in class 3 will be larger than the number of samples in the majority class (class #3 -> 27444)\n",
      "  warnings.warn(\n",
      "/Users/melvinakash/miniconda3/lib/python3.10/site-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (34000) in class 2 will be larger than the number of samples in the majority class (class #3 -> 27444)\n",
      "  warnings.warn(\n",
      "/Users/melvinakash/miniconda3/lib/python3.10/site-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (34000) in class 1 will be larger than the number of samples in the majority class (class #3 -> 27444)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Extract features and target variable\n",
    "X = data.drop('a_type', axis=1)  # Features\n",
    "y = data['a_type']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the desired number of samples for each class\n",
    "desired_samples = 34000  # Adjust this value according to your requirements\n",
    "\n",
    "# Set up the sampling strategy for each class\n",
    "sampling_strategy = {label: desired_samples for label in y_train.unique()}\n",
    "\n",
    "# Apply RandomOverSampler with the custom sampling strategy\n",
    "ros = RandomOverSampler(sampling_strategy=sampling_strategy, random_state=42)\n",
    "X_train_combined, y_train_combined = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd9ea3c",
   "metadata": {},
   "source": [
    "# Distribution after over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cd57fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    34000\n",
       "2    34000\n",
       "1    34000\n",
       "Name: a_type, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_combined.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade9ded8",
   "metadata": {},
   "source": [
    "# RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4b6ae7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with the best hyperparameters: 0.9864\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Defining the hyperparameters and their possible values for grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Performing Grid Search\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# Getting the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Training the model with the best hyperparameters\n",
    "best_model = RandomForestClassifier(**best_params)\n",
    "best_model.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with the best hyperparameters: {accuracy:.4f}\")\n",
    "\n",
    "# Performing Randomized Search (alternative to Grid Search)\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=10, cv=5,\n",
    "                                   scoring='accuracy', random_state=42)\n",
    "random_search.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# best hyperparameters from randomized search\n",
    "best_params_random = random_search.best_params_\n",
    "\n",
    "# Train the model with the best hyperparameters from randomized search\n",
    "best_model_random = RandomForestClassifier(**best_params_random)\n",
    "best_model_random.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred_random = best_model_random.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy_random = accuracy_score(y_test, y_pred_random)\n",
    "report_random = classification_report(y_test, y_pred_random)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c176a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with the best hyperparameters: 0.9864\n",
      "Classification Report for Random Forest with hyperparameter tuning:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.98      0.99       125\n",
      "           2       0.99      0.91      0.95      1193\n",
      "           3       0.98      1.00      0.99      6826\n",
      "\n",
      "    accuracy                           0.99      8144\n",
      "   macro avg       0.99      0.96      0.98      8144\n",
      "weighted avg       0.99      0.99      0.99      8144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy with the best hyperparameters: {accuracy:.4f}\")\n",
    "print(f\"Classification Report for Random Forest with hyperparameter tuning:\\n{report_random}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09f9d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix for RandomForestClassifier():\n",
    "confusion_mat = confusion_matrix(y_test, y_pred_random)\n",
    "print(f\"Confusion Matrix for RandomForestClassifier():\\n\")\n",
    "# Visualize the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(confusion_mat, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=['Class 1', 'Class 2', 'Class 3'],\n",
    "            yticklabels=['Class 1', 'Class 2', 'Class 3'])\n",
    "plt.title(f'Confusion Matrix for RandomForestClassifier()')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "print('=' * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10358ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best Hyperparameters for Decision Tree: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31b5a28",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ebdb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# Defining hyperparameters for Decision Tree\n",
    "param_grid_dt = {\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Performing Grid Search for Decision Tree\n",
    "grid_search_dt = GridSearchCV(dt_model, param_grid_dt, cv=5, scoring='accuracy')\n",
    "grid_search_dt.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# Getting the best hyperparameters for Decision Tree\n",
    "best_params_dt = grid_search_dt.best_params_\n",
    "\n",
    "# Training the Decision Tree model with the best hyperparameters\n",
    "best_dt_model = DecisionTreeClassifier(**best_params_dt)\n",
    "best_dt_model.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# Making predictions on the test set using Decision Tree\n",
    "y_pred_dt = best_dt_model.predict(X_test)\n",
    "\n",
    "# Evaluating the Decision Tree model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "report_dt = classification_report(y_test, y_pred_dt)\n",
    "\n",
    "#  Evaluating the model\n",
    "print(f\"Accuracy for Decision Tree with hyperparameter tuning: {accuracy_dt:.4f}\")\n",
    "print(f\"Best Hyperparameters for Decision Tree: {best_params_dt}\")\n",
    "print(f\"Classification Report for Decision Tree with hyperparameter tuning:\\n{report_dt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6862e15c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Confusion Matrix for DecisionTreeClassifier():\n",
    "confusion_mat = confusion_matrix(y_test, y_pred_dt)\n",
    "print(f\"Confusion Matrix for DecisionTreeClassifier():\\n\")\n",
    "# Visualize the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(confusion_mat, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=['Class 1', 'Class 2', 'Class 3'],\n",
    "            yticklabels=['Class 1', 'Class 2', 'Class 3'])\n",
    "plt.title(f'Confusion Matrix for DecisionTreeClassifier()')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "print('=' * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b965d74",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c16735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors (KNN)\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "# Defining hyperparameters for KNN\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "# Performing Grid Search for KNN\n",
    "grid_search_knn = GridSearchCV(knn_model, param_grid_knn, cv=5, scoring='accuracy')\n",
    "grid_search_knn.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# Get the best hyperparameters for KNN\n",
    "best_params_knn = grid_search_knn.best_params_\n",
    "\n",
    "# Training the KNN model with the best hyperparameters\n",
    "best_knn_model = KNeighborsClassifier(**best_params_knn)\n",
    "best_knn_model.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# Making predictions on the test set using KNN\n",
    "y_pred_knn = best_knn_model.predict(X_test)\n",
    "\n",
    "# Evaluating the KNN model\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "report_knn = classification_report(y_test, y_pred_knn)\n",
    "\n",
    "# Evaluating the model\n",
    "print(f\"Accuracy for K-Nearest Neighbors with hyperparameter tuning: {accuracy_knn:.4f}\")\n",
    "print(f\"Best Hyperparameters for K-Nearest Neighbors: {best_params_knn}\")\n",
    "print(f\"Classification Report for K-Nearest Neighbors with hyperparameter tuning:\\n{report_knn}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ff92b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix for KNeighborsClassifier():\n",
    "confusion_mat = confusion_matrix(y_test, y_pred_knn)\n",
    "print(f\"Confusion Matrix for KNeighborsClassifier():\\n\")\n",
    "# Visualize the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(confusion_mat, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=['Class 1', 'Class 2', 'Class 3'],\n",
    "            yticklabels=['Class 1', 'Class 2', 'Class 3'])\n",
    "plt.title(f'Confusion Matrix for KNeighborsClassifier()')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "print('=' * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52a0bee",
   "metadata": {},
   "source": [
    "# MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605acd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artificial Neural Network (ANN)\n",
    "ann_model = MLPClassifier()\n",
    "\n",
    "# Defining hyperparameters for ANN\n",
    "param_grid_ann = {\n",
    "    'hidden_layer_sizes': [(50, 25), (100, 50), (150, 75)],\n",
    "    'alpha': [0.0001, 0.001, 0.01]\n",
    "}\n",
    "\n",
    "# Performing Grid Search for ANN\n",
    "grid_search_ann = GridSearchCV(ann_model, param_grid_ann, cv=5, scoring='accuracy')\n",
    "grid_search_ann.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# Getting the best hyperparameters for ANN\n",
    "best_params_ann = grid_search_ann.best_params_\n",
    "\n",
    "# Train the ANN model with the best hyperparameters\n",
    "best_ann_model = MLPClassifier(**best_params_ann)\n",
    "best_ann_model.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# Making predictions on the test set using ANN\n",
    "y_pred_ann = best_ann_model.predict(X_test)\n",
    "\n",
    "# Evaluating the ANN model\n",
    "accuracy_ann = accuracy_score(y_test, y_pred_ann)\n",
    "report_ann = classification_report(y_test, y_pred_ann)\n",
    "\n",
    "# Evaluating the model\n",
    "print(f\"Accuracy for Artificial Neural Network with hyperparameter tuning: {accuracy_ann:.4f}\")\n",
    "print(f\"Best Hyperparameters for Artificial Neural Network: {best_params_ann}\")\n",
    "print(f\"Classification Report for Artificial Neural Network with hyperparameter tuning:\\n{report_ann}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61538b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix for MLPClassifier():\n",
    "confusion_mat = confusion_matrix(y_test, y_pred_ann)\n",
    "print(f\"Confusion Matrix for MLPClassifier()::\\n\")\n",
    "# Visualize the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(confusion_mat, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=['Class 1', 'Class 2', 'Class 3'],\n",
    "            yticklabels=['Class 1', 'Class 2', 'Class 3'])\n",
    "plt.title(f'Confusion Matrix for MLPClassifier()')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "print('=' * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1896226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
